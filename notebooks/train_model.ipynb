{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Model Training for Walmart Demand Prediction\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the training of demand prediction models using historical sales data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestRegressor\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Prepare Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load processed data\\n\",\n",
    "    \"df = pd.read_csv('../data/processed_sales_data.csv')\\n\",\n",
    "    \"df['date'] = pd.to_datetime(df['date'])\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Feature Engineering\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Create additional features\\n\",\n",
    "    \"df['year'] = df['date'].dt.year\\n\",\n",
    "    \"df['month'] = df['date'].dt.month\\n\",\n",
    "    \"df['day_of_week'] = df['date'].dt.dayofweek\\n\",\n",
    "    \"df['quarter'] = df['date'].dt.quarter\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create lag features\\n\",\n",
    "    \"df['lag_7'] = df.groupby(['region', 'product_id'])['sales_quantity'].shift(7)\\n\",\n",
    "    \"df['lag_14'] = df.groupby(['region', 'product_id'])['sales_quantity'].shift(14)\\n\",\n",
    "    \"df['lag_30'] = df.groupby(['region', 'product_id'])['sales_quantity'].shift(30)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create rolling mean features\\n\",\n",
    "    \"df['rolling_mean_7'] = df.groupby(['region', 'product_id'])['sales_quantity'].transform(lambda x: x.rolling(7, min_periods=1).mean())\\n\",\n",
    "    \"df['rolling_mean_14'] = df.groupby(['region', 'product_id'])['sales_quantity'].transform(lambda x: x.rolling(14, min_periods=1).mean())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Drop rows with NaN values (from lag features)\\n\",\n",
    "    \"df = df.dropna()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Prepare features and target\\n\",\n",
    "    \"feature_columns = [\\n\",\n",
    "    \"    'month', 'day_of_week', 'quarter', 'year',\\n\",\n",
    "    \"    'lag_7', 'lag_14', 'lag_30',\\n\",\n",
    "    \"    'rolling_mean_7', 'rolling_mean_14',\\n\",\n",
    "    \"    'price', 'promotion_flag'\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"X = pd.get_dummies(df[feature_columns], columns=['month', 'day_of_week', 'quarter'])\\n\",\n",
    "    \"y = df['sales_quantity']\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Train-Test Split\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Split data by time\\n\",\n",
    "    \"train_size = int(len(df) * 0.8)\\n\",\n",
    "    \"X_train = X[:train_size]\\n\",\n",
    "    \"X_test = X[train_size:]\\n\",\n",
    "    \"y_train = y[:train_size]\\n\",\n",
    "    \"y_test = y[train_size:]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training set size: {len(X_train)}\\\")\\n\",\n",
    "    \"print(f\\\"Test set size: {len(X_test)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Model Training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Initialize and train model\\n\",\n",
    "    \"model = RandomForestRegressor(\\n\",\n",
    "    \"    n_estimators=100,\\n\",\n",
    "    \"    max_depth=10,\\n\",\n",
    "    \"    random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"model.fit(X_train, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Make predictions\\n\",\n",
    "    \"y_pred = model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate metrics\\n\",\n",
    "    \"mae = mean_absolute_error(y_test, y_pred)\\n\",\n",
    "    \"mse = mean_squared_error(y_test, y_pred)\\n\",\n",
    "    \"r2 = r2_score(y_test, y_pred)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Mean Absolute Error: {mae:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Mean Squared Error: {mse:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"R2 Score: {r2:.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Importance Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Plot feature importance\\n\",\n",
    "    \"feature_importance = pd.DataFrame({\\n\",\n",
    "    \"    'feature': X.columns,\\n\",\n",
    "    \"    'importance': model.feature_importances_\\n\",\n",
    "    \"})\\n\",\n",
    "    \"feature_importance = feature_importance.sort_values('importance', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\\n\",\n",
    "    \"plt.title('Top 10 Most Important Features')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Save Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Save model and feature names\\n\",\n",
    "    \"model_data = {\\n\",\n",
    "    \"    'model': model,\\n\",\n",
    "    \"    'feature_names': X.columns.tolist(),\\n\",\n",
    "    \"    'feature_columns': feature_columns\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"joblib.dump(model_data, '../models/demand_model.pkl')\\n\",\n",
    "    \"print(\\\"Model saved to demand_model.pkl\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
